{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spaghetti!\n",
      "Python 3.7.11\n",
      "Num GPUs Available 0\n",
      "tf.Tensor(-105.06503, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('Spaghetti!')\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "!python --version\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available\", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 27 bad training samples\n",
      "Removed 27 training samples with text\n",
      "30585 training labels loaded\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "# Load the training images\n",
    "#####################################################\n",
    "\n",
    "# Load the training images and class labels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "IMG_SIZE = 299  # VGG16 224, InceptionV3 299\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 15\n",
    "\n",
    "# Classes which should be removed from the training set\n",
    "REMOVE_LABELS = ['20'] #['28', '55']\n",
    "\n",
    "# Filter for a subset of labels in the images to load\n",
    "FILTER_LABEL = []\n",
    "\n",
    "QUICK_DIRTY = True\n",
    "if QUICK_DIRTY:\n",
    "    IMG_SIZE = 112\n",
    "    BATCH_SIZE = 40\n",
    "    EPOCHS = 10\n",
    "    #Below are the 5 most unrepresented classes and the 5 most represented classes\n",
    "    FILTER_LABEL = [] \n",
    "    #27, 255, 257, 274, 278, 489, 490, 491, 494, 525\n",
    "    #FILTER_LABEL = ['1','2','3','4','5','6','7','8','9','10']\n",
    "\n",
    "# Local data directories\n",
    "DATA_DIR = 'C:\\Data\\DS_Data\\AML_Kaggle'\n",
    "TRAIN_DIR = DATA_DIR + '/train_set/'\n",
    "TEST_DIR = DATA_DIR + '/test_set/'\n",
    "MODEL_DIR = DATA_DIR + '/models/'\n",
    "\n",
    "# Maximum number of images to load (there are 30k), set to 0 for all\n",
    "MAX_IMAGE = 0\n",
    "\n",
    "# Load all the training labels\n",
    "train_labels = pd.read_csv(DATA_DIR + '/train_labels.csv', dtype={'label': object})\n",
    "if (len(FILTER_LABEL) > 0):\n",
    "    train_labels = train_labels[train_labels['label'].isin(FILTER_LABEL)].copy().reset_index()\n",
    "\n",
    "# Remove bad classes from the training data\n",
    "count = len(train_labels)\n",
    "train_labels = train_labels[~train_labels['label'].isin(REMOVE_LABELS)]\n",
    "print('Removed {} bad training samples'.format(count - len(train_labels)))\n",
    "NUM_CLASSES = len(train_labels.groupby('label').count())\n",
    "\n",
    "# Remove images with text from the training data\n",
    "#images_with_text = pd.read_csv('./images_with_text.csv')\n",
    "#count = len(train_labels)\n",
    "#train_labels = train_labels[~train_labels['img_name'].isin(images_with_text['img_name'])]\n",
    "print('Removed {} training samples with text'.format(count - len(train_labels)))\n",
    "NUM_CLASSES = len(train_labels.groupby('label').count())\n",
    "\n",
    "# Shuffle the training labels\n",
    "train_labels = shuffle(train_labels, random_state=3422545)\n",
    "\n",
    "print('{} training labels loaded'.format(len(train_labels)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24468 validated image filenames belonging to 79 classes.\n",
      "Found 6117 validated image filenames belonging to 79 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "# Create the data generators\n",
    "#####################################################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import adam\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "\n",
    "# Create a training and test set generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=10,#40\n",
    "        width_shift_range=0.1,#0.2\n",
    "        height_shift_range=0.1,#0.2\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1, #0.2\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_split = int(len(train_labels)*0.8)\n",
    "train_dataframe = train_labels[:train_split][['img_name','label']]\n",
    "val_dataframe = train_labels[train_split:][['img_name','label']]\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_dataframe,\n",
    "    x_col = 'img_name',\n",
    "    y_col = 'label',\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_dataframe,\n",
    "    x_col = 'img_name',\n",
    "    y_col = 'label',\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "# Early stopping callback, stops the training if there's no more progress\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_acc', \n",
    "    patience=3, \n",
    "    min_delta=0.001, \n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# Learning rate scheduler callback, decreases the LR during training\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch == 3:\n",
    "        lr = lr/10       # After 3 epochs, divide by 10\n",
    "    \n",
    "    if epoch == 6:\n",
    "        return lr/10\n",
    "\n",
    "    if epoch == 10:\n",
    "        return lr/10\n",
    "        \n",
    "    return lr\n",
    "\n",
    "lr_scheduler_callback = LearningRateScheduler(\n",
    "    lr_scheduler\n",
    ")\n",
    "\n",
    "# Model checkpoint callback, stores the model every few epochs during training\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    MODEL_DIR + 'model_checkpoint',\n",
    "    monitor=\"val_acc\",\n",
    "    verbose=1,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\"#,\n",
    "    #save_freq=\"epoch\"\n",
    ")\n",
    "\n",
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"acc\"])\n",
    "    plt.plot(hist.history[\"val_acc\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8393537099927961,\n",
       " 1: 0.84623365843536,\n",
       " 2: 0.9832429174201326,\n",
       " 3: 0.9385500575373993,\n",
       " 4: 1.352495716101929,\n",
       " 5: 0.8579543462253235,\n",
       " 6: 0.8172071741090812,\n",
       " 7: 0.9529892891918208,\n",
       " 8: 0.8303525978212916,\n",
       " 9: 1.1821432022417624,\n",
       " 10: 1.329276905525072,\n",
       " 11: 0.9163358549921354,\n",
       " 12: 1.1386820551005212,\n",
       " 13: 1.0754219409282701,\n",
       " 14: 0.8193690978501105,\n",
       " 15: 0.9739670408406974,\n",
       " 16: 1.1687604490088368,\n",
       " 17: 0.9273099370878496,\n",
       " 18: 1.098303258820361,\n",
       " 19: 1.243861522037517,\n",
       " 20: 0.8874542091327845,\n",
       " 21: 0.950066009163625,\n",
       " 22: 0.8555843065948667,\n",
       " 23: 1.1471167369901547,\n",
       " 24: 1.1958359806461072,\n",
       " 25: 1.1386820551005212,\n",
       " 26: 1.0829423740816146,\n",
       " 27: 1.14288383390163,\n",
       " 28: 0.8823974899924267,\n",
       " 29: 0.8003140025512707,\n",
       " 30: 0.7801549596658482,\n",
       " 31: 1.0534745543787134,\n",
       " 32: 1.0121618267560188,\n",
       " 33: 1.3888857353692456,\n",
       " 34: 1.0499034541943788,\n",
       " 35: 1.5409030795390137,\n",
       " 36: 0.9442729237418956,\n",
       " 37: 1.0606901335182937,\n",
       " 38: 1.0255679436666947,\n",
       " 39: 0.8900043649061545,\n",
       " 40: 1.0499034541943788,\n",
       " 41: 0.99269717624148,\n",
       " 42: 0.9190549524846937,\n",
       " 43: 1.3123793177429737,\n",
       " 44: 1.0055893473614992,\n",
       " 45: 1.2641694652544562,\n",
       " 46: 0.9029781894674688,\n",
       " 47: 0.8416345624656026,\n",
       " 48: 1.191236611489776,\n",
       " 49: 1.340785796481999,\n",
       " 50: 0.9163358549921354,\n",
       " 51: 0.794157740993184,\n",
       " 52: 0.9357145588741443,\n",
       " 53: 1.358427714856762,\n",
       " 54: 1.352495716101929,\n",
       " 55: 0.8675672800765876,\n",
       " 56: 0.7982513375962417,\n",
       " 57: 0.9739670408406974,\n",
       " 58: 0.9739670408406974,\n",
       " 59: 1.110112971280795,\n",
       " 60: 0.9163358549921354,\n",
       " 61: 1.285151531067808,\n",
       " 62: 1.5642500958956655,\n",
       " 63: 1.0463564830653438,\n",
       " 64: 0.9588901516635968,\n",
       " 65: 0.8215424906826042,\n",
       " 66: 1.0055893473614992,\n",
       " 67: 0.7103704563929857,\n",
       " 68: 0.8348288921491692,\n",
       " 69: 0.9958891285766617,\n",
       " 70: 0.7901059157840351,\n",
       " 71: 1.1600056890911676,\n",
       " 72: 1.2539332752523957,\n",
       " 73: 1.0121618267560188,\n",
       " 74: 1.4540916384382243,\n",
       " 75: 0.9245418477234083,\n",
       " 76: 0.9328961415281378,\n",
       " 77: 1.0606901335182937,\n",
       " 78: 0.796199277602421}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                 classes = np.unique(train_dataframe['label']),\n",
    "                                                 y = train_dataframe['label'])\n",
    "class_weights = dict(zip(np.unique(train_dataframe['label']), class_weights))\n",
    "class_weights\n",
    "\n",
    "\n",
    "real_weights = {}\n",
    "i = 0\n",
    "for num in np.unique(train_dataframe['label']):\n",
    "    real_weights[i] = class_weights[str(num)]\n",
    "    i+=1\n",
    "\n",
    "real_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DataFrameIterator at 0x2322918dac8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "305/305 [==============================] - 1693s 6s/step - loss: 3.8362 - acc: 0.1424 - val_loss: 2.9803 - val_acc: 0.2829\n",
      "Epoch 2/10\n",
      "305/305 [==============================] - 1701s 6s/step - loss: 2.7078 - acc: 0.3407 - val_loss: 2.3935 - val_acc: 0.4053\n",
      "Epoch 3/10\n",
      "305/305 [==============================] - 1596s 5s/step - loss: 2.1943 - acc: 0.4484 - val_loss: 2.2270 - val_acc: 0.4500\n",
      "Epoch 4/10\n",
      "305/305 [==============================] - 1573s 5s/step - loss: 1.9338 - acc: 0.5041 - val_loss: 2.1505 - val_acc: 0.4734\n",
      "Epoch 5/10\n",
      "305/305 [==============================] - 1569s 5s/step - loss: 1.7045 - acc: 0.5562 - val_loss: 2.0567 - val_acc: 0.4961\n",
      "Epoch 6/10\n",
      "305/305 [==============================] - 1568s 5s/step - loss: 1.5228 - acc: 0.6025 - val_loss: 2.0950 - val_acc: 0.5079\n",
      "Epoch 7/10\n",
      "305/305 [==============================] - 1558s 5s/step - loss: 1.3775 - acc: 0.6330 - val_loss: 2.1349 - val_acc: 0.4990\n",
      "Epoch 8/10\n",
      "305/305 [==============================] - 1560s 5s/step - loss: 1.2415 - acc: 0.6655 - val_loss: 2.0888 - val_acc: 0.5023\n",
      "Epoch 9/10\n",
      "305/305 [==============================] - 1560s 5s/step - loss: 1.1136 - acc: 0.6976 - val_loss: 2.0990 - val_acc: 0.5010\n",
      "Epoch 10/10\n",
      "305/305 [==============================] - 1566s 5s/step - loss: 0.9999 - acc: 0.7227 - val_loss: 2.1110 - val_acc: 0.5112\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################################################\n",
    "# Train Xception model\n",
    "##################################################\n",
    " \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define Tensorboard callback with dedicated log directory\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir, update_freq=1)\n",
    "\n",
    "def InitializeXceptionModel():\n",
    "    # Defining the pretrained base model\n",
    "    base = Xception(include_top=False, weights='imagenet', input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "    x = base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # On more dense layers + dropout, didn't improve at all\n",
    "    #x = Dense(1024, activation=\"relu\")(x) # Adding dense 512 + dropout lowered to 59%\n",
    "    #x = Dropout(0.1)(x)\n",
    "    # Defining the head of the model where the prediction is conducted\n",
    "    head = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    # Combining base and head \n",
    "    model = Model(inputs=base.input, outputs=head)\n",
    "\n",
    "    return model\n",
    "\n",
    "if 'model' in locals() or 'model' in globals():\n",
    "    if input('Train a fresh model?') == 'y':\n",
    "        print('Discarding current model')\n",
    "        model = InitializeXceptionModel()\n",
    "else:\n",
    "    model = InitializeXceptionModel()\n",
    "\n",
    "# Compiling the model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.0001), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "#class_weights = {\n",
    "#    #0 : 113.3778, \n",
    "#    0 : 12.00471,\n",
    "#    1 : 11.91128,\n",
    "#    2 : 11.17226,\n",
    "#    3 : 11.01151,\n",
    "#    4 : 10.77887324,\n",
    "#    5 : 6.260123,\n",
    "#    6 : 6.247347,\n",
    "#    7 : 6.234623,\n",
    "#    8 : 6.196761,\n",
    "#    9 : 5.830857\n",
    "#}\n",
    "\n",
    "#class_weights = {\n",
    "#    20 : 113.3778, \n",
    "#    42 : 12.00471,\n",
    "#    67 : 11.91128,\n",
    "#    78 : 11.17226,\n",
    "#    59 : 11.01151,\n",
    "#    9 : 6.260123,\n",
    "#    61 : 6.247347,\n",
    "#    57 : 6.234623,\n",
    "#    37 : 6.196761,\n",
    "#    71 : 5.830857\n",
    "#}\n",
    "\n",
    "hist = model.fit(\n",
    "    train_generator, \n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=int(len(train_dataframe)/BATCH_SIZE/2), \n",
    "    validation_data=val_generator, \n",
    "    validation_steps=int(len(val_dataframe)/BATCH_SIZE/2),\n",
    "    class_weight = real_weights, \n",
    "    verbose=1)#,\n",
    "    #callbacks=[early_stopping, tb_callback, lr_scheduler_callback, model_checkpoint_callback])\n",
    "\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Train InceptionV3 model \n",
    "##################################################\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "import datetime\n",
    "\n",
    "# Define Tensorboard callback with dedicated log directory\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir, update_freq=1)\n",
    "\n",
    "def InitializeInceptionV3Model():\n",
    "    pre_trained_model = InceptionV3(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top=False, weights = 'imagenet')\n",
    "\n",
    "    for layer in pre_trained_model.layers: \n",
    "        layer.trainable=False\n",
    "\n",
    "    x = layers.Flatten()(pre_trained_model.output)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(pre_trained_model.input, x)\n",
    "    return model\n",
    "\n",
    "if 'model' in locals() or 'model' in globals():\n",
    "    if input('Train a fresh model?') == 'y':\n",
    "        print('Discarding current model')\n",
    "        model = InitializeInceptionV3Model()\n",
    "else:\n",
    "    model = InitializeInceptionV3Model()\n",
    "    \n",
    "model.compile(\n",
    "    #optimizer = RMSprop(learning_rate=0.0001), \n",
    "    #optimizer = RMSprop(learning_rate=0.00005), \n",
    "    optimizer = RMSprop(learning_rate=0.000001), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['acc'])\n",
    "\n",
    "hist = model.fit(\n",
    "    train_generator, \n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=int(len(train_dataframe)/BATCH_SIZE/4), \n",
    "    validation_data=val_generator, \n",
    "    validation_steps=int(len(val_dataframe)/BATCH_SIZE/4),\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping, tb_callback])\n",
    "\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Fine tune InceptionV3 model\n",
    "##################################################\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(learning_rate=0.000005, momentum=0.9),\n",
    "                            loss='categorical_crossentropy',\n",
    "                            metrics=['acc'])\n",
    "\n",
    "hist = model.fit(\n",
    "    train_generator, \n",
    "    epochs=EPOCHS, \n",
    "    steps_per_epoch=int(len(train_dataframe)/BATCH_SIZE/4), \n",
    "    validation_data=val_generator, \n",
    "    validation_steps=int(len(val_dataframe)/BATCH_SIZE/4),\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping, tb_callback])                            \n",
    "\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#  Save the model\n",
    "#######################################################\n",
    "\n",
    "# TODO: model name in filename\n",
    "model.save(MODEL_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \n",
    "    'model.' + 'xception' +\n",
    "    '.' + str(NUM_CLASSES) + 'c.' +\n",
    "    str(IMG_SIZE) + 'px.69p-removed-0-classes.remove-0-ocr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#  Load a model\n",
    "#######################################################\n",
    "from tensorflow.keras import models\n",
    "\n",
    "#model = models.load_model(MODEL_DIR + 'model_checkpoint')\n",
    "model = models.load_model(MODEL_DIR + '20211205-122437model.xception.80c.299px.68p-2-classes-removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#  Classify the test set\n",
    "#######################################################\n",
    "\n",
    "# Classify\n",
    "test_generator.reset()\n",
    "probabilities = model.predict(test_generator)\n",
    "filenames = test_generator.filenames.copy()\n",
    "for i in range(0,len(filenames)):\n",
    "    filenames[i] = filenames[i][filenames[i].rfind('\\\\')+1:]\n",
    "predicted_class_indices = np.argmax(probabilities, axis=-1)\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "results=pd.DataFrame({\"img_name\":filenames,\n",
    "                      \"label\":predictions})\n",
    "\n",
    "results.to_csv(DATA_DIR + '/predictions.csv', index=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#  Look for confusing training images\n",
    "#######################################################\n",
    "\n",
    "train_set_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set_generator = train_set_datagen.flow_from_dataframe(\n",
    "    train_labels,\n",
    "    x_col = 'img_name',\n",
    "    y_col = 'label',\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=100,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Classify\n",
    "train_set_generator.reset()\n",
    "#probabilities = model.predict(train_set_generator, batch_size=32, verbose=1, steps=10, workers=2)\n",
    "probabilities = model.predict(train_set_generator, verbose=1, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#  Display the confusing training images\n",
    "#######################################################\n",
    "\n",
    "from PIL import Image\n",
    "fig, axs = plt.subplots(ncols=2, nrows=8)\n",
    "fig.set_size_inches(15, 30)\n",
    "\n",
    "# Show images that were hard to classify\n",
    "confidence_threshold = 0.3\n",
    "\n",
    "filenames = pd.DataFrame({'filename':train_set_generator.filenames.copy()})\n",
    "hard_images = filenames[np.max(probabilities, axis=1) < confidence_threshold]\n",
    "print('Found {} confusing training images at a {} confidence threshold'.format(len(hard_images), confidence_threshold))\n",
    "\n",
    "row = 0\n",
    "for idx in hard_images.sample(frac=1).index:\n",
    "    # Load image\n",
    "    img = Image.open(TRAIN_DIR + hard_images.loc[idx]['filename'])\n",
    "\n",
    "    # Plot image    \n",
    "    axs[row, 0].imshow(img)\n",
    "    #axs[row, 0].set_title('Class: ' + hard_images.loc[idx]['label'])\n",
    "\n",
    "    # Plot probabilities\n",
    "    axs[row, 1].plot(probabilities[idx])\n",
    "    axs[row, 1].set_title('Max:' + str(max(probabilities[idx])))\n",
    "\n",
    "    #print(label)\n",
    "    print(hard_images['filename'][idx])\n",
    "\n",
    "    row += 1\n",
    "    if row > 7:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#  Confusion matrix\n",
    "#######################################################\n",
    "\n",
    "val_generator.reset()\n",
    "\n",
    "# Get the ground truth\n",
    "filenames = val_generator.filenames.copy()\n",
    "labels = val_generator.labels.copy()\n",
    "\n",
    "# Predict classes\n",
    "probabilities = model.predict(val_generator, verbose=1, workers=2)\n",
    "predictions = np.argmax(probabilities, axis=-1)\n",
    "\n",
    "df_cm = pd.DataFrame({\n",
    "    'img_name': filenames,\n",
    "    'label_truth': labels,\n",
    "    'label_predict': predictions\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "cm = confusion_matrix(df_cm['label_truth'], df_cm['label_predict'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# Show the images of each class to debug bad training\n",
    "# images\n",
    "#######################################################\n",
    "\n",
    "NCOL = 5\n",
    "NROW = 32\n",
    "\n",
    "from PIL import Image\n",
    "fig, axs = plt.subplots(ncols=NCOL, nrows=NROW)\n",
    "fig.set_size_inches(20, 120)\n",
    "\n",
    "label = '12'\n",
    "df = train_labels[train_labels['label'] == label].sample(frac=1)\n",
    "print('Found {} images for class {}'.format(len(df), label))\n",
    "\n",
    "i = 0\n",
    "for row in range(0, NROW):\n",
    "    if i > len(df):\n",
    "        print('No more images')\n",
    "        break\n",
    "\n",
    "    for col in range(0, NCOL):\n",
    "        # Load image\n",
    "        img = Image.open(TRAIN_DIR + df.iloc[i]['img_name'])\n",
    "\n",
    "        # Plot image    \n",
    "        axs[row, col].imshow(img)\n",
    "        axs[row, col].xaxis.set_visible(False)\n",
    "        axs[row, col].yaxis.set_visible(False)\n",
    "        axs[row, col].set_title('Class: ' + df.iloc[i]['img_name'])\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#  Check which classes have the most problems - part 1\n",
    "#######################################################\n",
    "\n",
    "# Predict classes\n",
    "val_generator.reset()\n",
    "probabilities = model.predict(val_generator, verbose=1)\n",
    "predicted_label_indices = np.argmax(probabilities, axis=-1)\n",
    "\n",
    "# Get the ground truth\n",
    "filenames = val_generator.filenames.copy()\n",
    "truth_label_indices = val_generator.labels.copy()\n",
    "\n",
    "label_dict = (train_generator.class_indices)\n",
    "label_dict = dict((v,k) for k,v in label_dict.items())\n",
    "y_pred = [label_dict[k] for k in predicted_label_indices]\n",
    "y_truth = [label_dict[k] for k in truth_label_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#  Check which classes have the most problems - part 2\n",
    "#######################################################\n",
    "\n",
    "df_cm = pd.DataFrame({\n",
    "    'img_name': filenames,\n",
    "    'label_truth': y_truth,\n",
    "    'label_predict': y_pred\n",
    "    })\n",
    "    \n",
    "df_cm['correct'] = False\n",
    "df_cm.loc[df_cm['label_truth'] == df_cm['label_predict'], 'correct'] = True\n",
    "print(len(df_cm[df_cm['correct'] == True]))\n",
    "print(len(df_cm[df_cm['correct'] == False]))\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "class_report_mean = df_cm.groupby('label_truth').mean()['correct']\n",
    "class_report_count = df_cm.groupby('label_truth').count()['img_name']\n",
    "#class_report.plot()\n",
    "class_report = pd.DataFrame({\n",
    "    'count': class_report_count,\n",
    "    'correct': class_report_mean\n",
    "    })\n",
    "class_report.sort_values('correct', inplace=True)\n",
    "class_report['correct'].plot()\n",
    "print(class_report[:10])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "312b15c8e281011c15b3624d7e696b55e97b571d1c0e0ccfe711241545262bc8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ds': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
